{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_y3XpY_hw1hb"
      },
      "source": [
        "# Normalizing Flow Models\n",
        "\n",
        "**Author**: Chris Oswald\n",
        "\n",
        "**Course**: CS676/ECE689 Advanced Topics in Deep Learning (Spring 2024)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCKUlYQ0w1hk"
      },
      "source": [
        "## Question 1: Normalizing Flows\n",
        "\n",
        "- Select a coupling Normalizing Flow and an autoregressive Normalizing Flow (NF).\n",
        "- Apply the NF models to MNIST dataset.\n",
        "- You can resize the MNIST images to 7 × 7 pixels to reduce computational complexity.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cba-xUs4IJj_"
      },
      "source": [
        "## Set-up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCIgUfb3YCHm",
        "outputId": "3ed44d9d-ba72-478d-de7c-fde97bd5682d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSLBTZOww1hh"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRkI7f9aKCNA"
      },
      "outputs": [],
      "source": [
        "models_dir = \"./drive/MyDrive/Colab Notebooks/Models\"\n",
        "os.makedirs(models_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbqTTFeww1hf"
      },
      "source": [
        "## Imports and Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HezK0JVunY7U",
        "outputId": "beb13ace-8ab0-48ff-daa4-a0aacf895d15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting normflows\n",
            "  Downloading normflows-1.7.3.tar.gz (65 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/65.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.3/65.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from normflows) (1.25.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from normflows) (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->normflows) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->normflows) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->normflows) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->normflows) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->normflows) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->normflows) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->normflows) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->normflows) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->normflows) (1.3.0)\n",
            "Building wheels for collected packages: normflows\n",
            "  Building wheel for normflows (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for normflows: filename=normflows-1.7.3-py2.py3-none-any.whl size=87245 sha256=a3f45c9cc5f107fb3dc5faae7d8d6fd88c27f15fb76b7e01d981591fac80c03f\n",
            "  Stored in directory: /root/.cache/pip/wheels/08/b1/a6/f018e29f12dc6251793263911d14764ddad0a6844f7b024007\n",
            "Successfully built normflows\n",
            "Installing collected packages: normflows\n",
            "Successfully installed normflows-1.7.3\n"
          ]
        }
      ],
      "source": [
        "!pip install normflows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lEjedRvw1hf"
      },
      "outputs": [],
      "source": [
        "# Import packages\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "from torch.distributions.multivariate_normal import MultivariateNormal\n",
        "\n",
        "import normflows as nf\n",
        "\n",
        "import copy\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oUGzaiA5n9w",
        "outputId": "52722cc1-17cd-43c1-dc1a-b42cdae27201"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST/train/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 35408415.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting MNIST/train/MNIST/raw/train-images-idx3-ubyte.gz to MNIST/train/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST/train/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 52258711.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting MNIST/train/MNIST/raw/train-labels-idx1-ubyte.gz to MNIST/train/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST/train/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 26116921.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting MNIST/train/MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST/train/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST/train/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 7011604.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting MNIST/train/MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST/train/MNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Import resized MNIST data\n",
        "ds_MNIST_7 = torchvision.datasets.MNIST(\n",
        "    \"MNIST/train\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=torchvision.transforms.Compose([\n",
        "        torchvision.transforms.Resize(7),\n",
        "        torchvision.transforms.ToTensor(),\n",
        "    ])\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1kx2CI15n9w",
        "outputId": "0d84dccb-4b08-4cf9-8d8a-4aee1461e870"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: MNIST/train\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               Resize(size=7, interpolation=bilinear, max_size=None, antialias=warn)\n",
              "               ToTensor()\n",
              "           )"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds_MNIST_7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "iHrxzLtB5n9w",
        "outputId": "38ce5739-21ba-4f3e-a68a-89f5f9e129bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7f3e3f1b1f30>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Confirm that dataset was loaded\n",
        "first_image, first_label = ds_MNIST_7[0]\n",
        "first_image = first_image.numpy().transpose(1, 2, 0)\n",
        "image_plot = plt.imshow(first_image)\n",
        "plt.colorbar(image_plot, orientation=\"vertical\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-Enjd4u5n9w"
      },
      "source": [
        "References:\n",
        "\n",
        "- https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
        "- https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwoDIhcEqedz"
      },
      "source": [
        "## Coupling NF using `normflows` Package\n",
        "\n",
        "References:\n",
        "\n",
        "- https://github.com/VincentStimper/normalizing-flows/blob/master/examples/real_nvp.ipynb\n",
        "- https://github.com/VincentStimper/normalizing-flows/tree/master\n",
        "- https://arxiv.org/abs/1605.08803\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HwWmTkiVh7af"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(9999)\n",
        "n_flows = 64\n",
        "\n",
        "# Create flow layers\n",
        "n_dim =  ds_MNIST_7[0][0].flatten().shape[0]\n",
        "mask = torch.Tensor([1 if i % 2 == 0 else 0 for i in range(n_dim)])\n",
        "flows = []\n",
        "for i in range(n_flows):\n",
        "    s = nf.nets.MLP([n_dim, 128, n_dim], init_zeros=True)\n",
        "    t = nf.nets.MLP([n_dim, 128, n_dim], init_zeros=True)\n",
        "    if i % 2 == 0:\n",
        "        flows.append(nf.flows.MaskedAffineFlow(mask, t, s))\n",
        "    else:\n",
        "        flows.append(nf.flows.MaskedAffineFlow((1-mask), t, s))\n",
        "\n",
        "# Set base distribution\n",
        "base_dist = nf.distributions.DiagGaussian(n_dim)\n",
        "\n",
        "# Create model\n",
        "model = nf.NormalizingFlow(q0=base_dist, flows=flows)\n",
        "model = model.to(device).float()\n",
        "\n",
        "# Specify optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9NHZvfkh7SB",
        "outputId": "020a74a5-d031-4379-c9b9-28c542e5a9b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "----------\n",
            "Loss: 46.350960 [   64/60000]\n",
            "Loss: -38.612244 [ 6464/60000]\n",
            "Loss: -54.118797 [12864/60000]\n",
            "Loss: -16.705276 [19264/60000]\n",
            "Loss: -49.343594 [25664/60000]\n",
            "Loss: -66.319069 [32064/60000]\n",
            "Loss: -71.114601 [38464/60000]\n",
            "Loss: -36.772881 [44864/60000]\n",
            "Loss: -69.157990 [51264/60000]\n",
            "Loss: -74.999390 [57664/60000]\n",
            "Saved model for epoch 1\n",
            "Epoch 2\n",
            "----------\n",
            "Loss: -77.376366 [   64/60000]\n",
            "Loss: -80.536125 [ 6464/60000]\n",
            "Loss: -88.496643 [12864/60000]\n",
            "Loss: -93.090347 [19264/60000]\n",
            "Loss: -96.961960 [25664/60000]\n",
            "Loss: -91.442169 [32064/60000]\n",
            "Loss: -97.418610 [38464/60000]\n",
            "Loss: -96.233917 [44864/60000]\n",
            "Loss: 2.053486 [51264/60000]\n",
            "Loss: -30.322399 [57664/60000]\n",
            "Epoch 3\n",
            "----------\n",
            "Loss: -38.387138 [   64/60000]\n",
            "Loss: -45.206577 [ 6464/60000]\n",
            "Loss: -53.723839 [12864/60000]\n",
            "Loss: -62.587383 [19264/60000]\n",
            "Loss: -57.706299 [25664/60000]\n",
            "Loss: -69.507645 [32064/60000]\n",
            "Loss: -74.777267 [38464/60000]\n",
            "Loss: -81.065323 [44864/60000]\n",
            "Loss: -78.276810 [51264/60000]\n",
            "Loss: -78.559601 [57664/60000]\n",
            "Saved model for epoch 3\n",
            "Epoch 4\n",
            "----------\n",
            "Loss: -87.409225 [   64/60000]\n",
            "Loss: -84.617783 [ 6464/60000]\n",
            "Loss: -91.843132 [12864/60000]\n",
            "Loss: -95.619934 [19264/60000]\n",
            "Loss: -98.702293 [25664/60000]\n",
            "Loss: -8.881026 [32064/60000]\n",
            "Loss: 51.522125 [38464/60000]\n",
            "Loss: 20.284658 [44864/60000]\n",
            "Loss: -3.244694 [51264/60000]\n",
            "Loss: -11.973842 [57664/60000]\n",
            "Epoch 5\n",
            "----------\n",
            "Loss: -16.337555 [   64/60000]\n",
            "Loss: -22.288359 [ 6464/60000]\n",
            "Loss: -26.232586 [12864/60000]\n",
            "Loss: -37.226891 [19264/60000]\n",
            "Loss: -42.744484 [25664/60000]\n",
            "Loss: -47.174206 [32064/60000]\n",
            "Loss: -52.897186 [38464/60000]\n",
            "Loss: -59.082405 [44864/60000]\n",
            "Loss: -59.489761 [51264/60000]\n",
            "Loss: -64.226891 [57664/60000]\n",
            "Epoch 6\n",
            "----------\n",
            "Loss: -65.040779 [   64/60000]\n",
            "Loss: -65.748871 [ 6464/60000]\n",
            "Loss: -74.684677 [12864/60000]\n",
            "Loss: -72.893509 [19264/60000]\n",
            "Loss: -80.172119 [25664/60000]\n",
            "Loss: -82.448776 [32064/60000]\n",
            "Loss: -78.776375 [38464/60000]\n",
            "Loss: -80.299362 [44864/60000]\n",
            "Loss: -89.091537 [51264/60000]\n",
            "Loss: -87.138725 [57664/60000]\n",
            "Saved model for epoch 6\n",
            "Epoch 7\n",
            "----------\n",
            "Loss: -88.201698 [   64/60000]\n",
            "Loss: -93.837547 [ 6464/60000]\n",
            "Loss: -87.168549 [12864/60000]\n",
            "Loss: -91.855354 [19264/60000]\n",
            "Loss: -96.208687 [25664/60000]\n",
            "Loss: -95.453217 [32064/60000]\n",
            "Loss: -94.685150 [38464/60000]\n",
            "Loss: -90.460114 [44864/60000]\n",
            "Loss: -92.703278 [51264/60000]\n",
            "Loss: -97.270332 [57664/60000]\n",
            "Saved model for epoch 7\n",
            "Epoch 8\n",
            "----------\n",
            "Loss: -94.941780 [   64/60000]\n",
            "Loss: -101.660110 [ 6464/60000]\n",
            "Loss: -99.054565 [12864/60000]\n",
            "Loss: -99.344498 [19264/60000]\n",
            "Loss: -101.386047 [25664/60000]\n",
            "Loss: -105.764847 [32064/60000]\n",
            "Loss: -103.222382 [38464/60000]\n",
            "Loss: -111.252411 [44864/60000]\n",
            "Loss: -109.363831 [51264/60000]\n",
            "Loss: -109.842049 [57664/60000]\n",
            "Saved model for epoch 8\n",
            "Epoch 9\n",
            "----------\n",
            "Loss: -102.313431 [   64/60000]\n",
            "Loss: -109.601044 [ 6464/60000]\n",
            "Loss: -108.210045 [12864/60000]\n",
            "Loss: -110.508965 [19264/60000]\n",
            "Loss: -107.618134 [25664/60000]\n",
            "Loss: -111.438797 [32064/60000]\n",
            "Loss: -106.099869 [38464/60000]\n",
            "Loss: -107.977356 [44864/60000]\n",
            "Loss: -104.354706 [51264/60000]\n",
            "Loss: -113.578911 [57664/60000]\n",
            "Saved model for epoch 9\n",
            "Epoch 10\n",
            "----------\n",
            "Loss: -106.793625 [   64/60000]\n",
            "Loss: -112.436920 [ 6464/60000]\n",
            "Loss: -117.787292 [12864/60000]\n",
            "Loss: -114.585617 [19264/60000]\n",
            "Loss: -114.634521 [25664/60000]\n",
            "Loss: -115.099640 [32064/60000]\n",
            "Loss: -111.498199 [38464/60000]\n",
            "Loss: -117.063004 [44864/60000]\n",
            "Loss: -115.671539 [51264/60000]\n",
            "Loss: -115.876686 [57664/60000]\n",
            "Saved model for epoch 10\n",
            "Epoch 11\n",
            "----------\n",
            "Loss: -108.526932 [   64/60000]\n",
            "Loss: -117.940849 [ 6464/60000]\n",
            "Loss: -114.665497 [12864/60000]\n",
            "Loss: -113.834671 [19264/60000]\n",
            "Loss: -119.677879 [25664/60000]\n",
            "Loss: -116.152992 [32064/60000]\n",
            "Loss: -116.896622 [38464/60000]\n",
            "Loss: -118.110245 [44864/60000]\n",
            "Loss: -124.935120 [51264/60000]\n",
            "Loss: -120.625717 [57664/60000]\n",
            "Saved model for epoch 11\n",
            "Epoch 12\n",
            "----------\n",
            "Loss: -119.540215 [   64/60000]\n",
            "Loss: -122.283096 [ 6464/60000]\n",
            "Loss: -117.192581 [12864/60000]\n",
            "Loss: -120.886948 [19264/60000]\n",
            "Loss: -118.843834 [25664/60000]\n",
            "Loss: -124.032394 [32064/60000]\n",
            "Loss: -124.522919 [38464/60000]\n",
            "Loss: -126.268806 [44864/60000]\n",
            "Loss: -113.283813 [51264/60000]\n",
            "Loss: -119.954338 [57664/60000]\n",
            "Saved model for epoch 12\n",
            "Epoch 13\n",
            "----------\n",
            "Loss: -122.714142 [   64/60000]\n",
            "Loss: -128.104584 [ 6464/60000]\n",
            "Loss: -134.395157 [12864/60000]\n",
            "Loss: -124.422585 [19264/60000]\n",
            "Loss: -129.689148 [25664/60000]\n",
            "Loss: -126.266678 [32064/60000]\n",
            "Loss: -127.005852 [38464/60000]\n",
            "Loss: -121.183357 [44864/60000]\n",
            "Loss: -130.620560 [51264/60000]\n",
            "Loss: -122.411339 [57664/60000]\n",
            "Saved model for epoch 13\n",
            "Epoch 14\n",
            "----------\n",
            "Loss: -131.623459 [   64/60000]\n",
            "Loss: -119.255569 [ 6464/60000]\n",
            "Loss: -126.917755 [12864/60000]\n",
            "Loss: -117.424957 [19264/60000]\n",
            "Loss: -130.584671 [25664/60000]\n",
            "Loss: -123.539757 [32064/60000]\n",
            "Loss: -123.956032 [38464/60000]\n",
            "Loss: -125.227768 [44864/60000]\n",
            "Loss: -127.845428 [51264/60000]\n",
            "Loss: -127.640732 [57664/60000]\n",
            "Saved model for epoch 14\n",
            "Epoch 15\n",
            "----------\n",
            "Loss: -125.893661 [   64/60000]\n",
            "Loss: -133.754898 [ 6464/60000]\n",
            "Loss: -134.647705 [12864/60000]\n",
            "Loss: -127.866226 [19264/60000]\n",
            "Loss: -122.319534 [25664/60000]\n",
            "Loss: -125.464310 [32064/60000]\n",
            "Loss: -130.129486 [38464/60000]\n",
            "Loss: -127.433060 [44864/60000]\n",
            "Loss: -127.198692 [51264/60000]\n",
            "Loss: -132.444366 [57664/60000]\n",
            "Saved model for epoch 15\n",
            "Epoch 16\n",
            "----------\n",
            "Loss: -136.290894 [   64/60000]\n",
            "Loss: -127.430435 [ 6464/60000]\n",
            "Loss: -129.055801 [12864/60000]\n",
            "Loss: -122.274323 [19264/60000]\n",
            "Loss: -135.322220 [25664/60000]\n",
            "Loss: -136.163864 [32064/60000]\n",
            "Loss: -127.624802 [38464/60000]\n",
            "Loss: -133.013885 [44864/60000]\n",
            "Loss: -140.530731 [51264/60000]\n",
            "Loss: -127.852776 [57664/60000]\n",
            "Saved model for epoch 16\n",
            "Epoch 17\n",
            "----------\n",
            "Loss: -131.925049 [   64/60000]\n",
            "Loss: -135.467255 [ 6464/60000]\n",
            "Loss: -128.202835 [12864/60000]\n",
            "Loss: -135.603546 [19264/60000]\n",
            "Loss: -126.149384 [25664/60000]\n",
            "Loss: -126.162796 [32064/60000]\n",
            "Loss: -139.037003 [38464/60000]\n",
            "Loss: -135.774429 [44864/60000]\n",
            "Loss: -128.910690 [51264/60000]\n",
            "Loss: -138.836060 [57664/60000]\n",
            "Saved model for epoch 17\n",
            "Epoch 18\n",
            "----------\n",
            "Loss: -134.382812 [   64/60000]\n",
            "Loss: -130.020233 [ 6464/60000]\n",
            "Loss: -135.545074 [12864/60000]\n",
            "Loss: -130.354279 [19264/60000]\n",
            "Loss: -135.420822 [25664/60000]\n",
            "Loss: -126.819435 [32064/60000]\n",
            "Loss: -124.716721 [38464/60000]\n",
            "Loss: -136.611786 [44864/60000]\n",
            "Loss: -143.098663 [51264/60000]\n",
            "Loss: -131.489075 [57664/60000]\n",
            "Saved model for epoch 18\n",
            "Epoch 19\n",
            "----------\n",
            "Loss: -139.143372 [   64/60000]\n",
            "Loss: -137.325012 [ 6464/60000]\n",
            "Loss: -140.193298 [12864/60000]\n",
            "Loss: -130.863953 [19264/60000]\n",
            "Loss: -132.327271 [25664/60000]\n",
            "Loss: -136.928055 [32064/60000]\n",
            "Loss: -146.735168 [38464/60000]\n",
            "Loss: -137.469055 [44864/60000]\n",
            "Loss: -139.534241 [51264/60000]\n",
            "Loss: -149.330383 [57664/60000]\n",
            "Saved model for epoch 19\n",
            "Epoch 20\n",
            "----------\n",
            "Loss: -137.704834 [   64/60000]\n",
            "Loss: -137.310333 [ 6464/60000]\n",
            "Loss: -145.481750 [12864/60000]\n",
            "Loss: -137.950058 [19264/60000]\n",
            "Loss: -138.216003 [25664/60000]\n",
            "Loss: -141.126343 [32064/60000]\n",
            "Loss: -140.602051 [38464/60000]\n",
            "Loss: -140.968109 [44864/60000]\n",
            "Loss: -138.320953 [51264/60000]\n",
            "Loss: -147.737457 [57664/60000]\n",
            "Saved model for epoch 20\n"
          ]
        }
      ],
      "source": [
        "# Load/train model\n",
        "load_model = False\n",
        "load_model_name = \"\"\n",
        "load_model_path = os.path.join(models_dir, f\"{load_model_name}.pt\")\n",
        "\n",
        "if load_model:\n",
        "    if torch.cuda.is_available():\n",
        "        model.load_state_dict(torch.load(load_model_path))\n",
        "    else:\n",
        "        model.load_state_dict(\n",
        "            torch.load(load_model_path, map_location=torch.device(\"cpu\"))\n",
        "        )\n",
        "else:\n",
        "    batch_size = 64\n",
        "    epochs = 20\n",
        "\n",
        "    dl = DataLoader(ds_MNIST_7, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "    size = len(dl.dataset)\n",
        "\n",
        "    lowest_avg_loss = None\n",
        "\n",
        "    model.train()\n",
        "    for t in range(epochs):\n",
        "        loss_vals = []\n",
        "        print(f\"Epoch {t+1}\\n{'-'*10}\")\n",
        "        for batch, (X, _) in enumerate(dl):\n",
        "            X = X.to(device).view(batch_size, n_dim)\n",
        "\n",
        "            loss = model.forward_kld(X)\n",
        "\n",
        "            if ~(torch.isnan(loss) | torch.isinf(loss)):\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                # Record training batch loss\n",
        "                loss_val = loss.item()\n",
        "                loss_vals.append(loss_val)\n",
        "\n",
        "            # Report loss and current batch\n",
        "            if batch % 100 == 0:\n",
        "                current_batch = (batch + 1) * len(X)\n",
        "                print(f\"Loss: {loss_val:>7f} [{current_batch:>5d}/{size:>5d}]\")\n",
        "\n",
        "        # Save model if improving\n",
        "        epoch_avg_loss = np.mean(loss_vals)\n",
        "        if (lowest_avg_loss is None) or (epoch_avg_loss < lowest_avg_loss):\n",
        "            lowest_avg_loss = epoch_avg_loss\n",
        "            model.save(os.path.join(models_dir, f'CouplingNFmodel_epoch{t+1}.pt'))\n",
        "            print(f'Saved model for epoch {t+1}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "HsVtsYaeGgT3",
        "outputId": "d096e252-136f-4055-d8a8-07f01c964bec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x79a99e158b80>"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Sample from model\n",
        "z, _ = model.sample(1)\n",
        "z = z.to('cpu').view(7, 7).detach().numpy()\n",
        "plt.imshow(z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fHeLfYnAJlY"
      },
      "source": [
        "## Autoregressive NF using `normflows` Package"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bzsJsg35n9y"
      },
      "source": [
        "References:\n",
        "\n",
        "- https://github.com/VincentStimper/normalizing-flows/blob/master/normflows/flows/affine/autoregressive.py\n",
        "- https://github.com/bayesiains/nflows/blob/master/nflows/flows/autoregressive.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-52sqTXOYnT"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(8888)\n",
        "n_flows = 16 # Setting to 64 results in NaN loss values for all batches\n",
        "\n",
        "# Create flow layers\n",
        "n_dim =  ds_MNIST_7[0][0].flatten().shape[0]\n",
        "flows = []\n",
        "for i in range(n_flows):\n",
        "    flows.append(\n",
        "        nf.flows.MaskedAffineAutoregressive(\n",
        "            features=n_dim,\n",
        "            hidden_features=32,\n",
        "            use_batch_norm=True,\n",
        "        )\n",
        "    )\n",
        "\n",
        "# Set base distribution\n",
        "base_dist = nf.distributions.DiagGaussian(n_dim)\n",
        "\n",
        "# Create model\n",
        "model = nf.NormalizingFlow(q0=base_dist, flows=flows)\n",
        "model = model.to(device).float()\n",
        "\n",
        "# Specify optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXIIeQ_fRTCC",
        "outputId": "520e98e4-7ce6-4a65-b292-a079f0a1a027"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: -15.754591 [Epoch 1/20]\n",
            "Saved model for epoch 1\n",
            "Loss: -53.520104 [Epoch 2/20]\n",
            "Saved model for epoch 2\n",
            "Loss: -65.260176 [Epoch 3/20]\n",
            "Saved model for epoch 3\n",
            "Loss: -72.265711 [Epoch 4/20]\n",
            "Saved model for epoch 4\n",
            "Loss: -77.885487 [Epoch 5/20]\n",
            "Saved model for epoch 5\n",
            "Loss: -82.726488 [Epoch 6/20]\n",
            "Saved model for epoch 6\n",
            "Loss: -85.938771 [Epoch 7/20]\n",
            "Saved model for epoch 7\n",
            "Loss: -88.381940 [Epoch 8/20]\n",
            "Saved model for epoch 8\n",
            "Loss: -90.497325 [Epoch 9/20]\n",
            "Saved model for epoch 9\n",
            "Loss: -92.321800 [Epoch 10/20]\n",
            "Saved model for epoch 10\n",
            "Loss: -94.048842 [Epoch 11/20]\n",
            "Saved model for epoch 11\n",
            "Loss: -95.558981 [Epoch 12/20]\n",
            "Saved model for epoch 12\n",
            "Loss: -97.004938 [Epoch 13/20]\n",
            "Saved model for epoch 13\n",
            "Loss: -98.177051 [Epoch 14/20]\n",
            "Saved model for epoch 14\n",
            "Loss: -99.440532 [Epoch 15/20]\n",
            "Saved model for epoch 15\n",
            "Loss: -100.473484 [Epoch 16/20]\n",
            "Saved model for epoch 16\n",
            "Loss: -101.376469 [Epoch 17/20]\n",
            "Saved model for epoch 17\n",
            "Loss: -102.165986 [Epoch 18/20]\n",
            "Saved model for epoch 18\n",
            "Loss: -103.116388 [Epoch 19/20]\n",
            "Saved model for epoch 19\n",
            "Loss: -103.850959 [Epoch 20/20]\n",
            "Saved model for epoch 20\n"
          ]
        }
      ],
      "source": [
        "# Load/train model\n",
        "load_model = False\n",
        "load_model_name = \"\"\n",
        "load_model_path = os.path.join(models_dir, f\"{load_model_name}.pt\")\n",
        "\n",
        "if load_model:\n",
        "    if torch.cuda.is_available():\n",
        "        model.load_state_dict(torch.load(load_model_path))\n",
        "    else:\n",
        "        model.load_state_dict(\n",
        "            torch.load(load_model_path, map_location=torch.device(\"cpu\"))\n",
        "        )\n",
        "else:\n",
        "    batch_size = 128\n",
        "    epochs = 20\n",
        "\n",
        "    dl = DataLoader(ds_MNIST_7, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "    size = len(dl.dataset)\n",
        "\n",
        "    lowest_avg_loss = None\n",
        "\n",
        "    model.train()\n",
        "    for t in range(epochs):\n",
        "        batch_losses = []\n",
        "        for batch, (X, _) in enumerate(dl):\n",
        "            X = X.to(device).view(batch_size, n_dim)\n",
        "\n",
        "            loss = model.forward_kld(X)\n",
        "\n",
        "            if ~(torch.isnan(loss) | torch.isinf(loss)):\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "\n",
        "                # Record training batch loss\n",
        "                loss_val = loss.item()\n",
        "                batch_losses.append(loss_val)\n",
        "            else:\n",
        "                print(f'NaN/Inf loss for batch {batch}')\n",
        "\n",
        "        epoch_avg_loss = np.mean(batch_losses)\n",
        "        print(f\"Loss: {epoch_avg_loss:>7f} [Epoch {t+1}/{epochs}]\")\n",
        "\n",
        "        # Save model if improving\n",
        "        epoch_avg_loss = np.mean(batch_losses)\n",
        "        if (lowest_avg_loss is None) or (epoch_avg_loss < lowest_avg_loss):\n",
        "            lowest_avg_loss = epoch_avg_loss\n",
        "            model.save(os.path.join(models_dir, f'AutoRegNFmodel_epoch{t+1}.pt'))\n",
        "            print(f'Saved model for epoch {t+1}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "b27Dvvr-cj-_",
        "outputId": "434422af-4abc-4a39-b3b5-4ecd8442bf6b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x78c61d2b9f60>"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Sample from model\n",
        "z, _ = model.sample(2)\n",
        "z = z.view(2, 7, 7).to(\"cpu\").detach().numpy()\n",
        "plt.imshow(z[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7JPJuE1hF7W"
      },
      "source": [
        "## *Archived Attempts [For Reference]*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMhIayMCqvsF"
      },
      "source": [
        "### NF Model from Scratch\n",
        "\n",
        "References:\n",
        "\n",
        "- https://github.com/karpathy/pytorch-normalizing-flows\n",
        "- https://github.com/VincentStimper/normalizing-flows/tree/master"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZhUh5tzqCYYZ"
      },
      "outputs": [],
      "source": [
        "# class MLP(nn.Module):\n",
        "#     \"\"\"Multi-layer perceptron feedforward neural network\"\"\"\n",
        "\n",
        "#     def __init__(self, n_input: int, n_output: int, n_hidden: int = 64) -> None:\n",
        "#         \"\"\"\n",
        "#         Initializes sequential linear model with 2 hidden layers and\n",
        "#         leaky ReLU activation function.\n",
        "#         \"\"\"\n",
        "#         super().__init__()\n",
        "#         self.seq_net = nn.Sequential(\n",
        "#             nn.Linear(n_input, n_hidden),\n",
        "#             nn.LeakyReLU(0),\n",
        "#             nn.Linear(n_hidden, n_hidden),\n",
        "#             nn.LeakyReLU(0),\n",
        "#             nn.Linear(n_hidden, n_output)\n",
        "#         )\n",
        "\n",
        "#     def forward(self, x: torch.Tensor):\n",
        "#         output = self.seq_net(x)\n",
        "#         return output\n",
        "\n",
        "\n",
        "# class CNN(nn.Module):\n",
        "#     \"\"\"\n",
        "#     Based on: https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
        "#     \"\"\"\n",
        "\n",
        "#     def __init__(\n",
        "#         self,\n",
        "#         in_channels: int,\n",
        "#         height: int,\n",
        "#         width: int,\n",
        "#         n_output: int\n",
        "#     ) -> None:\n",
        "#         \"\"\"\n",
        "#         Initializes convolutional neural network model.\n",
        "#         \"\"\"\n",
        "#         super().__init__()\n",
        "#         self.seq_cnn = nn.Sequential(\n",
        "#             nn.Conv2d(in_channels, 6, (height, width)),\n",
        "#             nn.LeakyReLU(0),\n",
        "#             nn.MaxPool2d(2, 2),\n",
        "#             nn.Conv2d(6, 16, (height, width)),\n",
        "#             nn.LeakyReLU(0),\n",
        "#             nn.MaxPool2d(2, 2),\n",
        "#             nn.Conv2d(16, 24, (height, width)),\n",
        "#             nn.LeakyReLU(0),\n",
        "#             nn.MaxPool2d(2, 2),\n",
        "#             nn.Flatten(1, -1),\n",
        "#             nn.Linear(24 * height * width, 120),\n",
        "#             nn.Linear(120, 64),\n",
        "#             nn.Linear(64, n_output),\n",
        "#         )\n",
        "\n",
        "#     def forward(self, x: torch.Tensor):\n",
        "#         output = self.seq_cnn(x)\n",
        "#         return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pM3NtVWz5n9x"
      },
      "outputs": [],
      "source": [
        "# class AffineCouplingLayer(nn.Module):\n",
        "#     \"\"\"\n",
        "#     Affine coupling layer for RealNVP normalizing flow model.\n",
        "\n",
        "#     Primarily based on https://github.com/karpathy/pytorch-normalizing-flows.\n",
        "#     \"\"\"\n",
        "\n",
        "#     def __init__(self, dim: int, flip_order: bool):\n",
        "#         super().__init__()\n",
        "#         self.dim = dim\n",
        "#         self.flip_order = flip_order\n",
        "#         self.s_net = MLP((self.dim // 2), (self.dim // 2), 32)\n",
        "#         self.t_net = MLP((self.dim // 2), (self.dim // 2), 32)\n",
        "\n",
        "#     def forward(self, x: torch.Tensor):\n",
        "#         x = x.view((x.shape[0], -1))\n",
        "#         x0, x1 = x[:,::2], x[:,1::2] # Split tensor\n",
        "#         if self.flip_order:\n",
        "#             x0, x1 = x1, x0 # Alternate which sub-tensor is passed through identity matrix\n",
        "#         s = self.s_net(x0) # Calculate scale parameter\n",
        "#         t = self.t_net(x0) # Calculate shift parameter\n",
        "#         z0 = x0 # Pass sub-tensor through identity matrix\n",
        "#         z1 = torch.exp(s) * x1 + t # Transform other sub-tensor\n",
        "#         if self.flip_order:\n",
        "#             z0, z1 = z1, z0 # Restore order before concatenating together\n",
        "#         z = torch.cat([z0, z1], dim=1)\n",
        "#         log_det = torch.sum(s, dim=1)\n",
        "#         return z, log_det\n",
        "\n",
        "#     def backward(self, z: torch.Tensor):\n",
        "#         z0, z1 = z[:, ::2], z[:,1::2]\n",
        "#         if self.flip_order:\n",
        "#             z0, z1 = z1, z0\n",
        "#         s = self.s_net(z0)\n",
        "#         t = self.t_net(z0)\n",
        "#         x0 = z0\n",
        "#         x1 = (z1 - t) * torch.exp(-s) # Inverse transformation\n",
        "#         if self.flip_order:\n",
        "#             x0, x1 = x1, x0\n",
        "#         x = torch.cat([x0, x1], dim=1)\n",
        "#         log_det = torch.sum(-s, dim=1)\n",
        "#         return x, log_det\n",
        "\n",
        "# class NFModel(nn.Module):\n",
        "#     def __init__(self, base_dist, flows):\n",
        "#         super().__init__()\n",
        "#         self.base_dist = base_dist\n",
        "#         self.flows = nn.ModuleList(flows)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         log_det = torch.zeros(x.shape[0]).to(device)\n",
        "#         z_list = [x]\n",
        "#         for flow_idx, flow in enumerate(self.flows):\n",
        "#             x, log_det_i = flow(x)\n",
        "#             log_det += log_det_i\n",
        "#             # print(f'Log det type: {type(log_det)}')\n",
        "#             x = torch.nan_to_num(x, nan=0, posinf=3, neginf=-3)\n",
        "#             z_list.append(x)\n",
        "#         log_prob_pz = (\n",
        "#             self.base_dist.log_prob(z_list[-1]).view(x.size(0), -1).sum(1)\n",
        "#         )\n",
        "#         log_prob_pz = log_prob_pz\n",
        "#         return z_list, log_prob_pz, log_det\n",
        "\n",
        "#     def backward(self, z):\n",
        "#         log_det = torch.zeros(z.shape[0]).to(device)\n",
        "#         x_list = [z]\n",
        "#         for flow_idx, flow in enumerate(self.flows[::-1]):\n",
        "#             z, log_det_j = flow.backward(z)\n",
        "#             log_det += log_det_j\n",
        "#             x_list.append(z)\n",
        "#         return x_list, log_det\n",
        "\n",
        "#     def sample(self, n_samples):\n",
        "#         z = self.base_dist.sample((n_samples,))\n",
        "#         x_list, _ = self.backward(z)\n",
        "#         return x_list\n",
        "\n",
        "#     def save(self, path):\n",
        "#         torch.save(self.state_dict(), path)\n",
        "\n",
        "#     def load(self, path):\n",
        "#         self.load_state_dict(torch.load(path))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xI22EeN8msI7"
      },
      "outputs": [],
      "source": [
        "# n_flow_layers = 40\n",
        "# n_dim = ds_MNIST[0][0].reshape(-1).shape[0] # MNIST (height x width pixels)\n",
        "\n",
        "# mean_vec = torch.zeros(n_dim).to(device)\n",
        "# cov_mat = torch.eye(n_dim).to(device)\n",
        "# gaussian_prior = torch.distributions.MultivariateNormal(mean_vec, cov_mat) # pz(z) ~ MVN(0, I)\n",
        "# flows = [\n",
        "#     AffineCouplingLayer(dim=n_dim, flip_order=(idx % 2))\n",
        "#     for idx in range(n_flow_layers)\n",
        "# ]\n",
        "\n",
        "# model = NFModel(gaussian_prior, flows).to(device)\n",
        "# print(model)\n",
        "\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6q5LY-c5n9y"
      },
      "outputs": [],
      "source": [
        "# batch_size = 64\n",
        "# epochs = 50\n",
        "\n",
        "# dl = DataLoader(ds_MNIST, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "# size = len(dl.dataset)\n",
        "\n",
        "# lowest_avg_loss = None\n",
        "\n",
        "# model.train()\n",
        "# for t in range(epochs):\n",
        "#     loss_vals = []\n",
        "#     print(f\"Epoch {t+1}\\n{'-'*10}\")\n",
        "#     for batch, (X, _) in enumerate(dl):\n",
        "#         X = X.to(device)\n",
        "\n",
        "#         z_list, log_prob_pz, log_det = model(X)\n",
        "#         # print(f'Log det type: {type(log_det)}')\n",
        "#         # print(f'Log prob pz type: {type(log_prob_pz)}')\n",
        "\n",
        "#         log_prob = log_prob_pz + log_det\n",
        "#         # print(f'Log prob type: {type(log_prob)}')\n",
        "\n",
        "#         loss = -torch.mean(log_prob)\n",
        "#         # print(f'Loss type: {type(loss)}')\n",
        "\n",
        "#         model.zero_grad()\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "#         # Record training batch loss\n",
        "#         loss_val = loss.item()\n",
        "#         loss_vals.append(loss_val)\n",
        "#         if batch % 100 == 0:\n",
        "#             current_batch = (batch + 1) * len(X)\n",
        "#             print(f\"Loss: {loss_val:>7f} [{current_batch:>5d}/{size:>5d}]\")\n",
        "\n",
        "#     # Save model if improving\n",
        "#     epoch_avg_loss = np.mean(loss_vals)\n",
        "#     if (lowest_avg_loss is None) or (epoch_avg_loss < lowest_avg_loss):\n",
        "#         lowest_avg_loss = epoch_avg_loss\n",
        "#         model.save(os.path.join(models_dir, f'NFmodel_epoch{t}.pt'))\n",
        "#         print(f'Saved model for epoch {t}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5cdKnWKqdeW"
      },
      "outputs": [],
      "source": [
        "# # Sample from model\n",
        "# model.eval()\n",
        "# sampled_images = model.sample(1)\n",
        "\n",
        "# first_image = sampled_images[0].view((7, 7))\n",
        "# plt.imshow(first_image.cpu().detach().numpy())\n",
        "\n",
        "# final_image = sampled_images[-1].view((7, 7))\n",
        "# plt.imshow(final_image.cpu().detach().numpy())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
