{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f149dfd6-2621-4895-bbb0-67754780087c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "177bc3a2-7fd6-4aea-bfc8-0ab8e8665ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "seq_len = 100\n",
    "valid_share = 0.4\n",
    "min_response_val = 20 # (Arbitrary--based on simulated data)\n",
    "max_response_val = 50 # (Arbitrary--based on simulated data)\n",
    "torch.manual_seed(9999)\n",
    "np.random.seed(9998)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25cdb9b4-d14e-42ea-a4e1-6c66b840ddce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify directory/file paths\n",
    "data_dir = \"Data\"\n",
    "\n",
    "# sim_data_file = \"DIBS_simulated_fmri_var4model.csv\"\n",
    "sim_data_file = \"DIBS_simulated_fmri_VAR1_corr_model.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86f49383-2d52-4de6-9760-620bcb9c115b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available: 1\n",
      "GPU 1: NVIDIA TITAN Xp\n"
     ]
    }
   ],
   "source": [
    "# Check that CUDA GPUs are available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.cuda.current_device()\n",
    "    print(f'Number of GPUs available: {torch.cuda.device_count()}')\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f'GPU {i+1}: {torch.cuda.get_device_name(i)}')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available--using CPU instead.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bab7165-37c0-4554-a5a6-72e562d5d3f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.116246</td>\n",
       "      <td>16.565530</td>\n",
       "      <td>12.415547</td>\n",
       "      <td>18.299480</td>\n",
       "      <td>17.276543</td>\n",
       "      <td>15.754591</td>\n",
       "      <td>16.140283</td>\n",
       "      <td>16.699754</td>\n",
       "      <td>8.404268</td>\n",
       "      <td>11.854886</td>\n",
       "      <td>...</td>\n",
       "      <td>13.878511</td>\n",
       "      <td>6.417796</td>\n",
       "      <td>6.675971</td>\n",
       "      <td>12.511130</td>\n",
       "      <td>16.446791</td>\n",
       "      <td>15.229926</td>\n",
       "      <td>13.449784</td>\n",
       "      <td>10.026379</td>\n",
       "      <td>12.659897</td>\n",
       "      <td>16.061967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.792518</td>\n",
       "      <td>19.305758</td>\n",
       "      <td>18.432122</td>\n",
       "      <td>19.598789</td>\n",
       "      <td>19.390565</td>\n",
       "      <td>19.234885</td>\n",
       "      <td>19.216070</td>\n",
       "      <td>19.378951</td>\n",
       "      <td>17.712553</td>\n",
       "      <td>18.576233</td>\n",
       "      <td>...</td>\n",
       "      <td>18.885059</td>\n",
       "      <td>17.471678</td>\n",
       "      <td>17.575436</td>\n",
       "      <td>18.570558</td>\n",
       "      <td>19.305121</td>\n",
       "      <td>18.991407</td>\n",
       "      <td>18.677850</td>\n",
       "      <td>18.059543</td>\n",
       "      <td>18.527432</td>\n",
       "      <td>19.265571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.121983</td>\n",
       "      <td>19.876964</td>\n",
       "      <td>14.909188</td>\n",
       "      <td>18.882328</td>\n",
       "      <td>16.265094</td>\n",
       "      <td>16.886579</td>\n",
       "      <td>19.313189</td>\n",
       "      <td>14.342573</td>\n",
       "      <td>11.619733</td>\n",
       "      <td>14.133271</td>\n",
       "      <td>...</td>\n",
       "      <td>17.373623</td>\n",
       "      <td>9.282487</td>\n",
       "      <td>8.073071</td>\n",
       "      <td>12.552553</td>\n",
       "      <td>13.669796</td>\n",
       "      <td>14.597934</td>\n",
       "      <td>14.564002</td>\n",
       "      <td>11.974637</td>\n",
       "      <td>13.515495</td>\n",
       "      <td>16.382279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.791987</td>\n",
       "      <td>20.660207</td>\n",
       "      <td>18.516190</td>\n",
       "      <td>22.940047</td>\n",
       "      <td>22.370048</td>\n",
       "      <td>19.327175</td>\n",
       "      <td>20.404752</td>\n",
       "      <td>18.564065</td>\n",
       "      <td>14.274104</td>\n",
       "      <td>17.026338</td>\n",
       "      <td>...</td>\n",
       "      <td>19.755899</td>\n",
       "      <td>16.347811</td>\n",
       "      <td>14.717065</td>\n",
       "      <td>14.199868</td>\n",
       "      <td>17.602043</td>\n",
       "      <td>16.879330</td>\n",
       "      <td>15.547040</td>\n",
       "      <td>13.652054</td>\n",
       "      <td>15.554164</td>\n",
       "      <td>20.579689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.614162</td>\n",
       "      <td>16.734544</td>\n",
       "      <td>18.330194</td>\n",
       "      <td>23.063298</td>\n",
       "      <td>17.598805</td>\n",
       "      <td>19.865324</td>\n",
       "      <td>18.555408</td>\n",
       "      <td>18.876797</td>\n",
       "      <td>13.724560</td>\n",
       "      <td>15.565455</td>\n",
       "      <td>...</td>\n",
       "      <td>14.019824</td>\n",
       "      <td>10.375109</td>\n",
       "      <td>9.326729</td>\n",
       "      <td>11.398092</td>\n",
       "      <td>16.280734</td>\n",
       "      <td>18.053591</td>\n",
       "      <td>14.627125</td>\n",
       "      <td>13.729796</td>\n",
       "      <td>12.034983</td>\n",
       "      <td>18.283346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1          2          3          4          5  \\\n",
       "0  19.116246  16.565530  12.415547  18.299480  17.276543  15.754591   \n",
       "1  19.792518  19.305758  18.432122  19.598789  19.390565  19.234885   \n",
       "2  19.121983  19.876964  14.909188  18.882328  16.265094  16.886579   \n",
       "3  20.791987  20.660207  18.516190  22.940047  22.370048  19.327175   \n",
       "4  20.614162  16.734544  18.330194  23.063298  17.598805  19.865324   \n",
       "\n",
       "           6          7          8          9  ...        990        991  \\\n",
       "0  16.140283  16.699754   8.404268  11.854886  ...  13.878511   6.417796   \n",
       "1  19.216070  19.378951  17.712553  18.576233  ...  18.885059  17.471678   \n",
       "2  19.313189  14.342573  11.619733  14.133271  ...  17.373623   9.282487   \n",
       "3  20.404752  18.564065  14.274104  17.026338  ...  19.755899  16.347811   \n",
       "4  18.555408  18.876797  13.724560  15.565455  ...  14.019824  10.375109   \n",
       "\n",
       "         992        993        994        995        996        997  \\\n",
       "0   6.675971  12.511130  16.446791  15.229926  13.449784  10.026379   \n",
       "1  17.575436  18.570558  19.305121  18.991407  18.677850  18.059543   \n",
       "2   8.073071  12.552553  13.669796  14.597934  14.564002  11.974637   \n",
       "3  14.717065  14.199868  17.602043  16.879330  15.547040  13.652054   \n",
       "4   9.326729  11.398092  16.280734  18.053591  14.627125  13.729796   \n",
       "\n",
       "         998        999  \n",
       "0  12.659897  16.061967  \n",
       "1  18.527432  19.265571  \n",
       "2  13.515495  16.382279  \n",
       "3  15.554164  20.579689  \n",
       "4  12.034983  18.283346  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "data = pd.read_csv(os.path.join(data_dir, sim_data_file), header=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc941e6c-f942-4d40-99ee-e8b98d3e51e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "data = (data - min_response_val)/(max_response_val - min_response_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4107e6fb-31af-4753-b49e-d43551c05085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data:  (31, 1000) \n",
      "Test data:  (19, 1000)\n"
     ]
    }
   ],
   "source": [
    "# Shuffle data and create test dataset\n",
    "shuffled_idx = np.random.permutation(len(data))\n",
    "data = data.loc[shuffled_idx].reset_index(drop=True)\n",
    "\n",
    "train_data = data.loc[0:int(len(data) * (1-valid_share)), ]\n",
    "train_data.shape\n",
    "\n",
    "test_idx = [idx for idx in data.index if idx not in train_data.index]\n",
    "test_data = data.loc[test_idx, ]\n",
    "print(\"Train data: \", train_data.shape, \"\\nTest data: \", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e88cd508-a6f6-4d40-8dc2-6cf00ffcdb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# train input seqs:  27900 \n",
      "# train target seqs:  27900\n"
     ]
    }
   ],
   "source": [
    "# Create input and target sequences for training data\n",
    "train_input_seq = []\n",
    "train_target_seq = []\n",
    "\n",
    "\n",
    "for obs in range(len(train_data)):\n",
    "    obs_data = train_data.iloc[obs]\n",
    "    for i in range(len(obs_data) - seq_len):\n",
    "        train_input_seq.append(obs_data[i:i+seq_len].values)\n",
    "        train_target_seq.append(obs_data[i+seq_len])\n",
    "        i += 1\n",
    "print(\"# train input seqs: \", len(train_input_seq), \"\\n# train target seqs: \", len(train_target_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "890c19be-ce18-4227-8ed9-68227e20917a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27900, 100, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert sequences to PyTorch tensors\n",
    "train_input_tensor = torch.from_numpy(np.array(train_input_seq)).float().unsqueeze(-1)\n",
    "train_input_tensor = train_input_tensor.to(device) # Note that \"to\" method for tensors is not in-place operation (like it is for nn.Module/model below)\n",
    "train_input_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cea09fd-88e3-4815-87c0-e1e8e09a9f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27900, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target_tensor = torch.from_numpy(np.array(train_target_seq)).float().unsqueeze(-1)\n",
    "train_target_tensor = train_target_tensor.to(device) # Note that \"to\" method for tensors is not in-place operation (like it is for nn.Module/model below)\n",
    "train_target_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45539293-932c-410e-9608-7d4d003c6f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RNN model class\n",
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.rnn = nn.LSTM(input_size, hidden_size, num_layers=n_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "        hidden = (\n",
    "            torch.zeros(self.n_layers, batch_size, self.hidden_size).to(device),\n",
    "            torch.zeros(self.n_layers, batch_size, self.hidden_size).to(device)\n",
    "        )\n",
    "\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "\n",
    "        out = self.fc(out[:, -1, :])\n",
    "\n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "435589fb-3eea-4297-8f7c-0d316ce088d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (rnn): LSTM(1, 64, batch_first=True)\n",
       "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate model\n",
    "input_size = 1\n",
    "hidden_size = 64\n",
    "output_size = 1\n",
    "\n",
    "model = RNN(input_size, hidden_size, output_size, n_layers=1)\n",
    "model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01a0eb40-aee7-4e85-9129-7480689327e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.001\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43f6ed00-ec05-4268-b9b8-0c1af89f1ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27900, 100, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e845bca-5a3d-4c70-a47a-12518b83ffb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 100\n",
    "data_loader = DataLoader(train_input_tensor, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80f2a1a-ba6b-4455-8ff2-b6ed74a62dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Epoch: 1\n",
      "Epoch: 2\n",
      "Epoch: 3\n",
      "Epoch: 4\n",
      "Epoch: 5\n",
      "Epoch: 6\n",
      "Epoch: 7\n",
      "Epoch: 8\n",
      "Epoch: 9\n",
      "Epoch: 10\n",
      "Epoch: 11\n",
      "Epoch: 12\n",
      "Epoch: 13\n",
      "Epoch: 14\n",
      "Epoch: 15\n",
      "Epoch: 16\n",
      "Epoch: 17\n",
      "Epoch: 18\n",
      "Epoch: 19\n",
      "Epoch: 20\n",
      "Epoch: 21\n",
      "Epoch: 22\n",
      "Epoch: 23\n",
      "Epoch: 24\n",
      "Epoch: 25\n",
      "Epoch: 26\n",
      "Epoch: 27\n",
      "Epoch: 28\n",
      "Epoch: 29\n",
      "Epoch: 30\n",
      "Epoch: 31\n",
      "Epoch: 32\n",
      "Epoch: 33\n",
      "Epoch: 34\n",
      "Epoch: 35\n",
      "Epoch: 36\n",
      "Epoch: 37\n",
      "Epoch: 38\n",
      "Epoch: 39\n",
      "Epoch: 40\n",
      "Epoch: 41\n",
      "Epoch: 42\n",
      "Epoch: 43\n",
      "Epoch: 44\n",
      "Epoch: 45\n",
      "Epoch: 46\n",
      "Epoch: 47\n",
      "Epoch: 48\n",
      "Epoch: 49\n",
      "Epoch: 50\n",
      "Epoch: 51\n",
      "Epoch: 52\n",
      "Epoch: 53\n",
      "Epoch: 54\n",
      "Epoch: 55\n",
      "Epoch: 56\n",
      "Epoch: 57\n",
      "Epoch: 58\n",
      "Epoch: 59\n",
      "Epoch: 60\n",
      "Epoch: 61\n",
      "Epoch: 62\n",
      "Epoch: 63\n",
      "Epoch: 64\n",
      "Epoch: 65\n",
      "Epoch: 66\n",
      "Epoch: 67\n",
      "Epoch: 68\n",
      "Epoch: 69\n",
      "Epoch: 70\n",
      "Epoch: 71\n",
      "Epoch: 72\n",
      "Epoch: 73\n",
      "Epoch: 74\n",
      "Epoch: 75\n",
      "Epoch: 76\n",
      "Epoch: 77\n",
      "Epoch: 78\n",
      "Epoch: 79\n",
      "Epoch: 80\n",
      "Epoch: 81\n",
      "Epoch: 82\n",
      "Epoch: 83\n",
      "Epoch: 84\n",
      "Epoch: 85\n",
      "Epoch: 86\n",
      "Epoch: 87\n",
      "Epoch: 88\n",
      "Epoch: 89\n",
      "Epoch: 90\n",
      "Epoch: 91\n",
      "Epoch: 92\n",
      "Epoch: 93\n",
      "Epoch: 94\n",
      "Epoch: 95\n",
      "Epoch: 96\n",
      "Epoch: 97\n",
      "Epoch: 98\n",
      "Epoch: 99\n",
      "Epoch [100/1000], Loss: 0.0025\n",
      "Epoch: 100\n",
      "Epoch: 101\n",
      "Epoch: 102\n",
      "Epoch: 103\n",
      "Epoch: 104\n",
      "Epoch: 105\n",
      "Epoch: 106\n",
      "Epoch: 107\n",
      "Epoch: 108\n",
      "Epoch: 109\n",
      "Epoch: 110\n",
      "Epoch: 111\n",
      "Epoch: 112\n",
      "Epoch: 113\n",
      "Epoch: 114\n",
      "Epoch: 115\n",
      "Epoch: 116\n",
      "Epoch: 117\n",
      "Epoch: 118\n",
      "Epoch: 119\n",
      "Epoch: 120\n",
      "Epoch: 121\n",
      "Epoch: 122\n",
      "Epoch: 123\n",
      "Epoch: 124\n",
      "Epoch: 125\n",
      "Epoch: 126\n",
      "Epoch: 127\n",
      "Epoch: 128\n",
      "Epoch: 129\n",
      "Epoch: 130\n",
      "Epoch: 131\n",
      "Epoch: 132\n",
      "Epoch: 133\n",
      "Epoch: 134\n",
      "Epoch: 135\n",
      "Epoch: 136\n",
      "Epoch: 137\n",
      "Epoch: 138\n",
      "Epoch: 139\n",
      "Epoch: 140\n",
      "Epoch: 141\n",
      "Epoch: 142\n",
      "Epoch: 143\n",
      "Epoch: 144\n",
      "Epoch: 145\n",
      "Epoch: 146\n",
      "Epoch: 147\n",
      "Epoch: 148\n",
      "Epoch: 149\n",
      "Epoch: 150\n",
      "Epoch: 151\n",
      "Epoch: 152\n",
      "Epoch: 153\n",
      "Epoch: 154\n",
      "Epoch: 155\n",
      "Epoch: 156\n",
      "Epoch: 157\n",
      "Epoch: 158\n",
      "Epoch: 159\n",
      "Epoch: 160\n",
      "Epoch: 161\n",
      "Epoch: 162\n",
      "Epoch: 163\n",
      "Epoch: 164\n",
      "Epoch: 165\n",
      "Epoch: 166\n",
      "Epoch: 167\n",
      "Epoch: 168\n",
      "Epoch: 169\n",
      "Epoch: 170\n",
      "Epoch: 171\n",
      "Epoch: 172\n",
      "Epoch: 173\n",
      "Epoch: 174\n",
      "Epoch: 175\n",
      "Epoch: 176\n",
      "Epoch: 177\n",
      "Epoch: 178\n",
      "Epoch: 179\n",
      "Epoch: 180\n",
      "Epoch: 181\n",
      "Epoch: 182\n",
      "Epoch: 183\n",
      "Epoch: 184\n",
      "Epoch: 185\n",
      "Epoch: 186\n",
      "Epoch: 187\n",
      "Epoch: 188\n",
      "Epoch: 189\n",
      "Epoch: 190\n",
      "Epoch: 191\n",
      "Epoch: 192\n",
      "Epoch: 193\n",
      "Epoch: 194\n",
      "Epoch: 195\n",
      "Epoch: 196\n",
      "Epoch: 197\n",
      "Epoch: 198\n",
      "Epoch: 199\n",
      "Epoch [200/1000], Loss: 0.0015\n",
      "Epoch: 200\n",
      "Epoch: 201\n",
      "Epoch: 202\n",
      "Epoch: 203\n",
      "Epoch: 204\n",
      "Epoch: 205\n",
      "Epoch: 206\n",
      "Epoch: 207\n",
      "Epoch: 208\n",
      "Epoch: 209\n",
      "Epoch: 210\n",
      "Epoch: 211\n",
      "Epoch: 212\n",
      "Epoch: 213\n",
      "Epoch: 214\n",
      "Epoch: 215\n",
      "Epoch: 216\n",
      "Epoch: 217\n",
      "Epoch: 218\n",
      "Epoch: 219\n",
      "Epoch: 220\n",
      "Epoch: 221\n",
      "Epoch: 222\n",
      "Epoch: 223\n",
      "Epoch: 224\n",
      "Epoch: 225\n",
      "Epoch: 226\n",
      "Epoch: 227\n",
      "Epoch: 228\n",
      "Epoch: 229\n",
      "Epoch: 230\n",
      "Epoch: 231\n",
      "Epoch: 232\n",
      "Epoch: 233\n",
      "Epoch: 234\n",
      "Epoch: 235\n",
      "Epoch: 236\n",
      "Epoch: 237\n",
      "Epoch: 238\n",
      "Epoch: 239\n",
      "Epoch: 240\n",
      "Epoch: 241\n",
      "Epoch: 242\n",
      "Epoch: 243\n",
      "Epoch: 244\n",
      "Epoch: 245\n",
      "Epoch: 246\n",
      "Epoch: 247\n",
      "Epoch: 248\n",
      "Epoch: 249\n",
      "Epoch: 250\n",
      "Epoch: 251\n",
      "Epoch: 252\n",
      "Epoch: 253\n",
      "Epoch: 254\n",
      "Epoch: 255\n",
      "Epoch: 256\n",
      "Epoch: 257\n",
      "Epoch: 258\n",
      "Epoch: 259\n",
      "Epoch: 260\n",
      "Epoch: 261\n",
      "Epoch: 262\n",
      "Epoch: 263\n",
      "Epoch: 264\n",
      "Epoch: 265\n",
      "Epoch: 266\n",
      "Epoch: 267\n",
      "Epoch: 268\n",
      "Epoch: 269\n",
      "Epoch: 270\n",
      "Epoch: 271\n",
      "Epoch: 272\n",
      "Epoch: 273\n",
      "Epoch: 274\n",
      "Epoch: 275\n",
      "Epoch: 276\n",
      "Epoch: 277\n",
      "Epoch: 278\n",
      "Epoch: 279\n",
      "Epoch: 280\n",
      "Epoch: 281\n",
      "Epoch: 282\n",
      "Epoch: 283\n",
      "Epoch: 284\n",
      "Epoch: 285\n",
      "Epoch: 286\n",
      "Epoch: 287\n",
      "Epoch: 288\n",
      "Epoch: 289\n",
      "Epoch: 290\n",
      "Epoch: 291\n",
      "Epoch: 292\n",
      "Epoch: 293\n",
      "Epoch: 294\n",
      "Epoch: 295\n",
      "Epoch: 296\n",
      "Epoch: 297\n",
      "Epoch: 298\n",
      "Epoch: 299\n",
      "Epoch [300/1000], Loss: 0.0010\n",
      "Epoch: 300\n",
      "Epoch: 301\n",
      "Epoch: 302\n",
      "Epoch: 303\n",
      "Epoch: 304\n",
      "Epoch: 305\n",
      "Epoch: 306\n",
      "Epoch: 307\n",
      "Epoch: 308\n",
      "Epoch: 309\n",
      "Epoch: 310\n",
      "Epoch: 311\n",
      "Epoch: 312\n",
      "Epoch: 313\n",
      "Epoch: 314\n",
      "Epoch: 315\n",
      "Epoch: 316\n",
      "Epoch: 317\n",
      "Epoch: 318\n",
      "Epoch: 319\n",
      "Epoch: 320\n",
      "Epoch: 321\n",
      "Epoch: 322\n",
      "Epoch: 323\n",
      "Epoch: 324\n",
      "Epoch: 325\n",
      "Epoch: 326\n",
      "Epoch: 327\n",
      "Epoch: 328\n",
      "Epoch: 329\n",
      "Epoch: 330\n",
      "Epoch: 331\n",
      "Epoch: 332\n",
      "Epoch: 333\n",
      "Epoch: 334\n",
      "Epoch: 335\n",
      "Epoch: 336\n",
      "Epoch: 337\n",
      "Epoch: 338\n",
      "Epoch: 339\n",
      "Epoch: 340\n",
      "Epoch: 341\n",
      "Epoch: 342\n",
      "Epoch: 343\n",
      "Epoch: 344\n",
      "Epoch: 345\n",
      "Epoch: 346\n",
      "Epoch: 347\n",
      "Epoch: 348\n",
      "Epoch: 349\n",
      "Epoch: 350\n",
      "Epoch: 351\n",
      "Epoch: 352\n",
      "Epoch: 353\n",
      "Epoch: 354\n",
      "Epoch: 355\n",
      "Epoch: 356\n",
      "Epoch: 357\n",
      "Epoch: 358\n",
      "Epoch: 359\n",
      "Epoch: 360\n",
      "Epoch: 361\n",
      "Epoch: 362\n",
      "Epoch: 363\n",
      "Epoch: 364\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    start_idx = 0\n",
    "    for end_idx in np.arange(batch_size, train_input_tensor.shape[0]+1, step=batch_size):\n",
    "\n",
    "        inputs = train_input_tensor[start_idx:end_idx].to(device)\n",
    "        labels = train_target_tensor[start_idx:end_idx].to(device)\n",
    "        start_idx += batch_size\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        output, hidden = model(inputs)\n",
    "        # print(epoch, output.shape, train_target_tensor.shape, train_target_tensor.view(-1).shape)\n",
    "        # print(epoch, hidden.shape)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch: {epoch}')\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a34727-f7c8-41cb-a167-300c1684041d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predicted values for training data\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    train_predictions, _ = model(train_input_tensor)\n",
    "train_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d25c574-28c5-491d-9128-40670bf2c87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute MSE for training data\n",
    "train_target_tensor = train_target_tensor.cpu()\n",
    "train_predictions = train_predictions.cpu()\n",
    "\n",
    "train_mse = (sum((train_target_tensor - train_predictions)**2))/len(train_predictions)\n",
    "train_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e277dda-ee21-4b94-9311-5cbaf6b9a110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot train predictions against actuals\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(\n",
    "    x=train_target_tensor.cpu(),\n",
    "    y=train_predictions.cpu(),\n",
    "    alpha=0.1\n",
    ")\n",
    "ax.axline([0, 0], [1, 1], linestyle=\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cc4a28-ba84-4e2e-8257-6c5477c1abd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input and target sequences for test data\n",
    "test_input_seq = []\n",
    "test_target_seq = []\n",
    "\n",
    "for obs in range(len(test_data)):\n",
    "    obs_data = test_data.iloc[obs]\n",
    "    for i in range(len(obs_data) - seq_len):\n",
    "        test_input_seq.append(obs_data[i:i+seq_len].values)\n",
    "        test_target_seq.append(obs_data[i+seq_len])\n",
    "        i += 1\n",
    "print(\"# test input seqs: \", len(test_input_seq), \"\\n# test target seqs: \", len(test_target_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef727dc9-5fb7-49a9-94e4-37dc79695b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert test sequences to PyTorch tensors\n",
    "test_input_tensor = torch.from_numpy(np.array(test_input_seq)).float().unsqueeze(-1)\n",
    "test_input_tensor = test_input_tensor.to(device) # Note that \"to\" method for tensors is not in-place operation (like it is for nn.Module/model below)\n",
    "test_input_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd921b7-d68e-4072-90fd-cd5e9a54e98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_target_tensor = torch.from_numpy(np.array(test_target_seq)).float().unsqueeze(-1)\n",
    "test_target_tensor = test_target_tensor.to(device) # Note that \"to\" method for tensors is not in-place operation (like it is for nn.Module/model below)\n",
    "test_target_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bcc860-f96e-48e6-b23c-c264d2a890ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for test data\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_predictions, _ = model(test_input_tensor)\n",
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a276ca-6450-4070-a7e4-d6870f62b59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute MSE for test data\n",
    "test_target_tensor = test_target_tensor.cpu()\n",
    "test_predictions = test_predictions.cpu()\n",
    "\n",
    "test_mse = (sum((test_target_tensor - test_predictions)**2))/len(test_predictions)\n",
    "test_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21690aaa-0fb2-46e9-bbd2-f6b969199f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot test predictions against actuals\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(\n",
    "    x=test_target_tensor.cpu(),\n",
    "    y=test_predictions.cpu(),\n",
    "    alpha=0.1\n",
    ")\n",
    "ax.axline([0, 0], [1, 1], linestyle=\"--\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
